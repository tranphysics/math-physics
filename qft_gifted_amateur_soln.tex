\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}	% Para caracteres en espa√±ol
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{braket}
\usepackage{multirow,booktabs}
\usepackage[table]{xcolor}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{wrapfig}
\usepackage{setspace}
\usepackage{calc}
\usepackage{multicol}
\usepackage{cancel}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\newlength{\tabcont}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}
\usepackage{empheq}
\usepackage{framed}
\usepackage[most]{tcolorbox}
\usepackage{xcolor}
\colorlet{shadecolor}{orange!15}
\parindent 0in
\parskip 12pt
\geometry{margin=1in, headsep=0.25in}
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{reg}{Rule}
\newtheorem{exer}{Exercise}
\newtheorem{note}{Note}
\begin{document}
\setcounter{section}{8}
\title{QFT Gifted amateur}

\thispagestyle{empty}

\begin{center}
{\LARGE \bf QFT for gifted amateur probelms}\\
2023
\end{center}


\section{Problems}
\subsection{Problem 2.3}

\begin{align}
x_j & \equiv {1 \over \sqrt{N}} \sum_k e^{i j k a} \tilde{x}_k \\
&= {1 \over \sqrt{N}} \sum_k  \sqrt{\hbar \over 2 m \omega_k} e^{i j k a} \left(a_k + a^{\dagger}_k \right) \\
&= {1 \over \sqrt{N}} \sum_k \sqrt{\hbar \over 2 m \omega_k} \left( a_k e^{ijka} + \underbrace{a^{\dagger}_{-k} e^{-ijka}}_{\text{swap k $\rightarrow$ -k}} \right)
\end{align}

\subsection{Problem 3.3}

First we will calculate $\frac12 m \omega^2 x_1^2 + {1 \over 2 m} p_1^2$:

\begin{align}
x_1 &\equiv \sqrt{\hbar \over 2 m \omega} (a_1 + a_1^\dagger) \\
p_1 &\equiv -i \sqrt{m \omega \hbar \over 2} (a_1 - a_1^\dagger) \\
\frac12 m \omega^2 x_1^2 + {1 \over 2 m} p_1^2 &=  \hbar \omega (\frac12 (a_1 a_1^\dagger + a_1^\dagger a_1)) \\
& = \hbar \omega \left(a_1^\dagger a_1 + \frac12 \right)
\end{align}

Since the "1" above is just label, it follows this must be true for "2" and "3" as well so that:
\begin{align}
\hat{H} = \hbar \omega \sum_{n=1}^3 \left(a_n^\dagger a_n + \frac12 \right)
\end{align}

To prove the next step, first note that $[b_0, b_{\text{anything else}}] = 0$ because $a_3$ commutes with $a_2, a_1$.  
Also note $[b_0, b_0^\dagger] = 1$.

Therefore, $[b_i, b_j^\dagger] = \delta_{ij}$ holds for i = 0.

For $i=-1, +1$, we only have to check, the following 3 calculations:

\emph{Calculation 1:}
\begin{align}
[b_{-1}, b_{+1}^\dagger] & = -\frac12 [a_1 +  i a_2, a_1^\dagger + i a_2^\dagger] \\
& = \frac12 \left( [a_1, a_1^\dagger] - [a_2, a_2^\dagger] \right) = 0
\end{align}

\emph{Calculation 2:}
\begin{align}
[b_{-1}, b_{-1}^\dagger] & = \frac12 [a_1 +  i a_2, a_1^\dagger - i a_2^\dagger] \\
& = \frac12 \left( [a_1, a_1^\dagger] + [a_2, a_2^\dagger] \right) = 1
\end{align}

\emph{Calculation 3:}
\begin{align}
[b_{+1}, b_{+1}^\dagger] & = \frac12 [a_1 -  i a_2, a_1^\dagger + i a_2^\dagger] \\
& = \frac12 \left( [a_1, a_1^\dagger] + [a_2, a_2^\dagger] \right) = 1
\end{align}

We now calculate the claimed hamiltonian:

\begin{align}
\hbar \omega \sum_m \left(b_m^\dagger b_m + \frac 12 \right) & = \hbar \omega (a_3^\dagger a_3 ) + \frac32 
\hbar \omega \times \frac12 (a_1^\dagger a_1 + a_2^\dagger a_2 + \text{cross terms}) + 
\hbar \omega \times \frac12 (a_1^\dagger a_1 + a_2^\dagger a_2 + \text{cross terms}) \\
& = \hbar \omega \sum_n (a_n^\dagger a_n + \frac12)
\end{align}

To check the 2nd claim, we note that the $m=0$ term goes away, while the $m=1$ and $m=-1$ term subtract.  This means we keep the cross terms from the previous calculation:

\begin{align}
\hbar \sum_{m=-1}^{+1} m b_m^\dagger b_m &= \hbar ( b_{+1}^\dagger b_{+1} - b_{-1}^\dagger b_{-1}) \\
& = -i \hbar \left(a_1^\dagger a_2 - a_2^\dagger a_1 \right) = \hat{L}^3
\end{align}

\emph{Commentary}

This problem illustrates a special case of the more general symmetry of the 3-d harmonic oscillator hamiltonian under U(3) group:
\begin{align}
\mathbf{a} \equiv (a_1, a_2, a_3)  \\
\rightarrow \mathbf{U} \mathbf{a} \rightarrow \hat{H} \rightarrow \hat{H}
\end{align}


\newpage
\subsection{Problem 5.4}

\begin{align}
L =-mc^2 \sqrt{1 - {v^2 \over c^2}} \approx -mc^2 \left(1 - {v^2 \over 2 c^2} \right) \approx -mc^2 + \frac12 m v^2 
\end{align}


\begin{align}
p & \equiv {\partial L \over \partial \dot{q}} \\
&= mv
\end{align}

\begin{align}
H &\equiv p \dot{q} - L \\
&= mv^2 - (-mc^2 + \frac12 mv^2) = mc^2 + \frac12 m v^2
\end{align}

\subsection{Problem 5.8}

Note that the electromagnetic field tensor, doing $\epsilon^{\alpha \beta \gamma \delta} F_{\gamma \delta}$ basically swaps $ E \rightarrow -B$ and $B \rightarrow -E$.

Then we are asked to compute $F_{\alpha \beta} \left(\epsilon^{\alpha \beta \gamma \delta } F_{\gamma \delta} \right)$ which is just the sum of all the matrix entries element wise multiplied, which gives:
$\propto \sum_{i=1}^3 E_i (-B_i) \propto E \cdot B$

This $E \cdot B$ term is topological in nature. The way to see it is in form notation, it can be written as $F \wedge F$.  Its integral over the manifold gives the winding number of the gauge field configuration and is a topological invariant.  It's integral over a closed manifold gives an integer (up to factors of pi and 2).

Another comment: this term obviously violates parity (by nature of having the $\epsilon$ tensor). 

\subsection{Problem 5.9}

Consider the equation:
$ \partial_{\mu} F^{\mu \nu} = J^{\nu}$ for $\nu = 0$

This gives:

\begin{align}
\partial_{x} E_x + \partial_y E_y + \partial_z E_z = \rho \text{ (Gauss's Law)}
\end{align}

Let's work out the same equation for $\nu = 1$ (x) component:

\begin{align}
 \partial_t E_x + \partial_y B_z - \partial_z B_y = J_x \\
\partial_t E_y - \partial_x B_z + \partial_z B_x = J_y \\
\text{et cetera} \\
\rightarrow \nabla \times \mathbf{B} + \partial_t \mathbf{E}  = \mathbf{J}
\end{align}

The bianchi's identity below:

\begin{align}
\partial_{[\mu}F_{\nu \lambda]} = 0
\end{align}

follows straight from the definition of F:

\begin{align}
F_{\nu \lambda} = \partial_{\nu} A_{\lambda} - \partial_{\lambda} A_{\nu}
\end{align}

A way to see it is that an exact form is necessarily closed:
$F = d A \rightarrow dF = 0$.

In particular for the spatial components $\mu, \nu, \lambda = 1, 2, 3$ it implies:
\begin{align}
\nabla \cdot \mathbf{B} = 0
\end{align}
which is one of maxwell's equations (no magnetic monopoles).

For the combination $\mu, \nu, \lambda = 0, (1 \rightarrow 3), (1 \rightarrow 3)$ where $\nu \neq \lambda$, we can for example use the case $0, 1, 3$ to get the following equation:

\begin{align}
\partial_0 F_{13} + \partial_{1} F_{30} + \partial_3 F_{01} &= 0 \\
\partial_t B_y - \partial_x E_z + \partial_z E_x = 0 \\
\end{align}

We can work out the 2 other cases for $B_x, B_z$ to get Faraday's law:

\begin{align}
\partial_t \mathbf{B} + \nabla \times \mathbf{E} = 0.
\end{align}

\subsection{Problem 5.10}

F is a anti-symmetric object.  It is contracted with symmetric tensor $\partial_\alpha \partial_\beta$ which implies that the result is 0
(this is because for every term, there is a term of opposite sign).

The continuity equation is a statement about conservation of charge:

\begin{align}
\partial_t \rho = - \nabla \cdot \mathbf{J} \rightarrow {d  \over dt} \underbrace{\int_{M} \rho dV}_{\text{charge in region "M"}} = - \underbrace{\int_{\partial M} \mathbf{J} \cdot d \mathbf{A}}_{\text{current flowing out of the boundary of }M}
\end{align}

\subsection{Problem 8.2}
Set $\hbar = 1$ for simplicity.
\begin{align}
a_k^{\dagger}(t) &= U^{-1} a_k^{\dagger}(0) U \\
& = \exp(i H t) a_k^{\dagger} \exp(-i Ht)\\
& = \exp(i \sum_{k'} E_{k'}\hat{N}_{k'} t ) a^{\dagger}\exp(-i \sum_{k'} E_{k'} \hat{N}_{k'} t )
\end{align}

Since the operators commute for $k' \neq k$, we only need to consider the term where k' = k.

We invoke the BCH formula to evaluate:

\begin{align}
a^{\dagger}_k(t) &= a_k^{\dagger}(0) + [i t E_k N_k, a_k(0)] + \frac12  [i t E_k N_k, [i t E_k N_k, a_k(0)]] + ... \\
& = a_k^{\dagger}(0) \times \left(\sum_{n = 0}^{\infty} {(it E_k)^n \over n!} \right) \\
& = a_k^{\dagger}(0) \times \exp(i E_k t)
\end{align}

It follows

\begin{align}
a_k(t) = a_k(0) \exp(-i E_k t)
\end{align}

\subsection{Problem 9.1}

\begin{align}
\hat{U} = e^{-i \hat{p}a} \rightarrow {\partial \over \partial a} \hat{U}|_{a= 0} = {i \hat{p}} \underbrace{U(0)}_{1} \rightarrow \hat{p } = {-1 \over i} {\partial \hat{U} \over \partial a}
\end{align}

\subsection{Problem 9.2}

\begin{equation*}
\Lambda(\phi_1) = 
\begin{pmatrix}
\cosh(\phi) & \sinh(\phi) & 0 & 0 \\
\sinh(\phi) & \cosh(\phi) & 0  & 0\\
0 & 0 & 0  & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}
\end{equation*}

\begin{align}
{\partial \over \partial \phi_1}|_{\phi_1 = 0} = 
\begin{pmatrix}
0 & 1& 0 & 0 \\
1 & 0 & 0  & 0\\
0 & 0 & 0  & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}
\end{align}

The other generators are obtained trivially by plugging "1" into the location $\Lambda^{0}_{j}$ and $\Lambda^{j}_{0}$ with $j = 1,2,3$.   Add the ${1 \over i}$ to get the answer.  Note how the generator are anti-hermitian (which makes the lie group non-compact).

\subsection{Problem 9.4}

\begin{align}
\omega^{\mu}_\nu x^\nu \partial_\mu & = \omega_{\mu \nu} x^\nu \partial^\mu \\
& = \underbrace{\frac12 \omega_{\mu \nu} x^\nu \partial^\mu + \frac12 \omega_{\mu \nu} x^\nu \partial^\mu}_{\text{split in 2}} \\
& = \frac12 \omega_{\mu \nu} x^\nu \partial^\mu \underbrace{- \frac12 \omega_{\nu \mu}}_{\text{anti-symmetry}} x^\nu \partial^\mu \\
& = \frac12 \omega_{\mu \nu} \left(x^\nu \partial^\mu - \underbrace{x^\mu \partial^\nu}_{\text{swap index}} \right)
\end{align}

\begin{align}
f(x') &= 1 + a^\mu \partial_\mu f(x) + \frac12 \omega_{\mu \nu}  \left(x^\nu \partial^\mu - x^\mu \partial^\nu \right) \\
& = 1 + i a^\mu \underbrace{(i \partial_\mu)}_{p_\mu} f(x) + {i \over 2 } \omega_{\mu \nu} \times \underbrace{ -i \left(x^\nu \partial^\mu - x^\mu \partial^\nu \right)}_{M^{\mu \nu}} f(x)
\end{align}

Because $\frac12 M^{\mu \nu}$ is the generator of lorentz transformation, the equation follows:

\begin{align}
\Lambda = \exp(-{i \over 2} \omega_{\mu \nu} M^{\mu \nu} )
\end{align}


\subsection{Why keep factors of $\hbar$}

One reason to keep factors of $\hbar$ around is to clarify when doing a semi-classical expansion. The classical limit of the quantum theory is obtained by taking $\hbar \rightarrow 0$, so in some sense, a classical expansion usually is carried out with an expansion around ${1 \over \hbar}$.

\paragraph{Example: WKB approximation}

The WKB approximationj is an expansion in $\hbar$ with the first order producing tunneling amplitude.  In some sense, it reproduces, it is a semi-classical expansion because as the wavelength decreases relative to the size of the variation of the potential term (large action relative to $\hbar$), the expansion becomes more accurate.

$$\psi(x) \propto \exp \left({i \over \hbar} \left(\int dx p(x) + \underbrace{\sum_{n=1}^\infty \hbar^n S_n}_{\text{higher order WKB terms}}  \right) \right) $$
$$ p(x) \equiv \sqrt{2 m (E-V(x))}$$

\paragraph{Example: Saddle point integration of the path integral}

Consider the typical path integral for some transition amplitude
$$\braket{\psi_f | e^{i Ht \over \hbar} | \psi_i} \equiv \int \mathcal{D} \phi \exp\left( {i \over \hbar} S[\phi] \right)$$
This amplitude can be approximated using the saddle point method around the path of least action $\phi_0$ (a minimum) in the limit of $\hbar \rightarrow 0$.  To do so, we parametrize field fluctuations around the minimum path:
$$ \phi(x)=\phi_0 + \sqrt{\hbar \over i} \epsilon(x)$$
where fluctuations $\epsilon$ is order 1 and we explicitly keep $\hbar$ to to show the expansion is small.

$$S[\phi] \approx \underbrace{S[\phi_0]}_{S_0} + {\hbar \over i} \underbrace {{\delta^2 \over \delta \phi(x) \delta \phi(y)} S[\phi]}_{\text{Hessian of S}} \epsilon(x) \epsilon(y) + ...$$
$$ \braket{\psi_f | e^{i Ht \over \hbar} | \psi_i} \approx \exp\left({i \over \hbar} S_0 \right) \exp \left(\frac12 \text{Tr} \ln({\delta^2 \over \delta \phi(x) \delta \phi(y)} S[\phi]\right) \int \mathcal{D}\phi \text{...} $$

The expansion in the limit $\hbar$ goes to 0 shows that the saddle point contribution is the dominant classical limit amplitude.


\subsection{Canonical quantization}

\paragraph{Why is setting the commutation relation between conjugate variables to $i \hbar$ the correct recipe to obtaining a quantum theory from a classical theory?}

There are many ways to attack this issue.  The most simple way I can think of quantizing a field is to realize that QFT is just the quantum theory of a continuum of particles.  Consider the classical theory of a single particle, with coordinate $\phi_1$ and momentum $\dot{\pi}_1$ with a hamiltonian of a harmonic oscillator:
$$H_1 = \frac12 m \omega^2 \phi_1^2 + \frac12 m \dot{\phi_1}^2 = \frac12 m \omega^2 \phi_1^2 + {\pi_1^2 \over 2 m} $$

The quantum theory of this single particle in a spring is described by a hamiltonian operator:

$$\hat{H}_1 = \frac12 m \omega^2 \hat{\phi}_1^2 + {\hat{\pi}_1^2 \over 2 m}$$
where $\hat{\phi}_1, \hat{\pi}_1$ are position momentum operators with commutation relation
$$ [\hat{\phi}_1, \hat{\pi}_1] = i \hbar$$


Now let's try to take a limit of an infinite number of springs connected together.  This is the theory of a solid lattice:

\subsection{Time dependent Hamiltonian}

The \emph{retarded} propagator $G^+(x, x', t, t')$ is defined as position space basis representation of the time evolution operator $\mathbf{U}$, restricted to positive times:


\begin{align}
\mathbf{U} (t, t') \ket{\psi(t')} &\equiv \ket{\psi(t)} \\
G^+(x, x', t, t') &\equiv \bra{x} \mathbf{U}(t, t') \ket{x'} \theta(t - t')
\end{align}

We can show that the time evolution operator satisfies schrodinger equation in operator form as:
\begin{align}
\mathbf{H U} = i \partial_t \mathbf{U}
\end{align}
In the text, if you use this relation you can show the retarded propagator satisfies a schrodinger PDE as well:
\begin{align}
\mathbf{H} G^+(x, x', t, t') = i \partial_t G^+ + i \delta(x - x') \delta(t - t')
\end{align}

where here the notation $\mathbf{H} G^+$ is understood as the operator H acting on the function G in the coordinate x and t (for example, if H had momentum squared terms, you'd get $\partial_x^2$ operator).

\subsection{Time-independent Hamiltonian}

In the case where the hamiltonian is time independent, we can obtain more interesting relations.  One particular representation we will derive is the fourier representation of the retarded propagator gives key information about the eigenfunctions and eigenvalues of the (time-independent) hamiltonian.

First, WLOG, set $t' = 0$.

If $\mathbf{H}(t) = \mathbf{H}$, $\mathbf{U}(t, t' = 0) = e^{-i \mathbf{H} t}$.
We now derive the fourier decomposition of the retarded propagator (which is a function of 3 variables now, initial and end position and time):

\begin{align}
G^+(x, x', t) &\equiv \bra{x} e^{-i \mathbf{H}t} \ket{x'}  \theta(t) 
\end{align}
We can introduce the set of eigenstates $\ket{n}$ of $\mathbf{H}$, satisfying: $\mathbf{H}\ket{n} = E_n \ket{n}$.  Since $\ket{n}$ forms a complete basis, we have:
\begin{align}
 \mathbf{I} & = \sum_n \ket{n} \bra{n} \\
G^{+} (x, x', t)& = \sum_{n, n'} \braket{x | n} \bra{n}e^{-i \mathbf{H}t} \ket{n'} \braket{n' | x'} \theta(t) \\
\end{align}

Note $\mathbf{H}$ is diagonal in the $\ket{n}$ basis.  Define $\phi_n(x) \equiv \braket{x | n}$.  This becomes

\begin{align}
G^{+} (x, x', t)& = \sum_{n, n'} \phi_n(x) e^{-i E_{n'} t} \underbrace{\braket{n | n'}}_{\delta_{n n'}} \phi_{n'}^*(x') \theta(t) \\
&=\theta(t) \sum_n \phi_n(x) \phi_n^*(x') e^{- i E_n t} 
\end{align}

The next step is to compute the fourier transform of $G^+$ with respect to time.  This would be straightforward, if not for the pesky $\theta$ factor, so we have to establish a few basic facts about complex integration.

We can re-express the exponential in this expression using the Cauchy integral formula.  Let's first establish a math fact as follow.
Consider the function f(E) below (this function is called a "Resolvent"):
\begin{align}
f(E) = \int_{-\infty}^\infty dz {e^{- i z t} \over z - E + i \epsilon}
\end{align}
It turns out this function neatly expresses the $\theta$ function due to the fact it is discontinuous from $t<0$ to $t>0$.  In fact, it is:
\begin{align}
f(E) = - 2 \pi i \theta(t) e^{- i E t}
\end{align}

\paragraph{digression on math identity}
\emph{
The way to see this math identity is that $ t < 0$, we can close the contour in the upper half plane.  This contour doesn't contain the $E - i\epsilon$ pole and therefore the closed curve integral is 0.  When $t > 0$, we have to close the contour in the lower half plane to make the semicircle contribution decay, and this cause the closed contour integral to contain the $E - i \epsilon$ pole, giving a non-zero contribution.  This is where the $\theta(t)$ factor comes in.}

Anyways using this identity, we can neatly repackage equation 63:

\begin{align}
G^+(x, x', t) = {i \over 2 \pi}\int_{-\infty}^\infty dz e^{-i zt} \underbrace{ \sum_n {\phi_n(x) \phi_n^*(x') \over z - E_n + i \epsilon}}_{\text{fourier component}}
\end{align}

Equation 66 is actually a fourier decomposition formula.  It shows that the fourier transform of the retarded propagator with respect to time $\tilde{G}$ is:

\begin{align}
\tilde{G}(x, x', E) \equiv \sum_n {i \phi_n(x) \phi_n^*(x') \over E - E_n + i \epsilon} \\
G^+(x, x', t) = \int {dE \over 2 \pi} e^{-i E t} \tilde{G}(x, x', E) 
\end{align}

Note that standard fourier decomposition formula for a function $f(t)$ uses frequencies $\omega$ with a $+$ sign, so $E \rightarrow -\omega$ in the formula above.
$$ f(t) = \int {d \omega \over 2 \pi} \tilde{f}(\omega) e^{i \omega t}$$

\paragraph{Interpretation of $G(x, x', E)$}:
$G(x, x', E)$ can be interpreted as the response function to a sinusoidal (over time) drive of the schrodinger equation.  To illustrate this fact, it may be easiest to work with a simple example.  Consider a simple ODE like that of a damped spring: $$({d^2 \over dt^2} + \lambda {d \over dt} +  \omega_0^2) y = f(t)$$
The impulse response function (green) function of this system is some damped oscillation. The fourier transform of this green function is a function of the form:
$$G(\omega) = {1 \over i \lambda \omega - \omega^2 + \omega_0^2}$$
This is a resonance curve that gives the frequency response of the spring: the amplitude / phase of the spring sinusoidal response to a driving force $f(t)$ at frequency $\omega$.

Furthermore, $\tilde{G}(x, x', E)$ in the expression above can be written as the coordinate reprensation of an operator $\mathbf{\tilde{G}}$.
This abstract operator $\mathbf{\tilde{G}}$ can be expressed neatly in terms of the eigen vectors $\ket{n}$ of the hamiltonian:
\begin{align}
\mathbf{\tilde{G}}(E) &\equiv \sum_{n} {i \ket{n} \bra{n} \over E - E_n + i \epsilon} \\
G(x, x', E) &= \braket{x| \mathbf{\tilde{G}}(E)| x'}
\end{align}

When written in the basis of $\ket{n}$, the operator looks diagonal.  It is obvious in that basis that the operator satisfies this simple equation:
\begin{align}
(E - \mathbf{H}) \mathbf{\tilde{G}}(E) =i \mathbf{I}
\end{align}
(it is understood in the expression above $E \equiv E \times \mathbf{I}$ since E is a scalar)

The coordinate representation of the equation above is:
\begin{align}
(E - \mathbf{H}) \tilde{G}(x, x', E) = i \delta(x - x')
\end{align}
(it is understood $\mathbf{H}$ operator applies on the coordinate x, leaving x' intact).  

\subsection{Green Function in Perturbation theory}
Consider now a case where one cannot solve the green function for the time-independent Hamiltonian exactly.  For example, suppose you know how to solve the problem for $\mathbf{H_0}$ but it is "perturbed" by a small perturbation $\Delta \mathbf{H}$:
 $$\mathbf{H} = \mathbf{H_0} + \Delta \mathbf{H}$$

We will now build a perturbation series for the green function for $\tilde{\mathbf{G}}$ for $\mathbf{H}$, given the green function $\tilde{\mathbf{G_0}}$ for $\mathbf{H_0}$.

We start from equation (72), the central identity:
$$ (E- \mathbf{H}) \mathbf{\tilde{G}} = i \mathbf{I}$$

To compute a perturbation expansion we solve this equation recursively:

\begin{align}
\mathbf{\tilde{G}} &= {i \mathbf{I} \over E - \mathbf{H}} \\
& = {i \mathbf{I} \over E - \mathbf{H_0} - \Delta \mathbf{H}} \\
& = {i \mathbf{I} \over E - \mathbf{H_0}} \left(\mathbf{I} - {\mathbf{\Delta H} \over E - \mathbf{H_0}} + \left({\mathbf{\Delta H} \over E - \mathbf{H_0}} \right)^2 ...\right)
\end{align}

This series solution has a (Feynman) diagrammatic representation: the "full" propagator looks like the free propagator with "interaction" terms $\Delta \mathbf{H}$ perturbing it.  Summing the whole geometric series gives you the exact solution.  A simple application of this series solution is for scattering problems, where the first order term is the so called \textbf{Born approximation}.

\subsection{On the green function as a complex function of energy}
\newcommand{\tG}{\mathbf{\tilde{G}}}
Let's discuss further the properties of the object $\tG$(E) as a function of a complex variable in general $\tG(z)$.  Consider a typical quantum well, where $V(x)$ is bounded from above, where without loss of generality we set $V(x) < 0$ for all $x$

For such a potential you get a set of bound states and a continuous spectrum of travelling waves for positive energies.  We introduce the following notation for the spectrum and the choice of orthogonal basis vectors of the hamiltonian.
\begin{itemize}
\item A discrete spectrum $E_n$ labelled by integer $n$, where states are labelled by $n, l$  where $l$ could be additional quantum numbers (hardness, colors, spin, whatever): $ \mathbf{H} \ket{n, l} = E_n \ket{n, l}$ 
\item A continuous spectrum $\rho \in (0, \infty)$, with states labelled by $\rho, l$:  $\mathbf{H} \ket{\rho, l} = \rho \ket{\rho, l}$
\end{itemize}

The object $\tG (z)$ can be more precisely written as
\begin{align}
\tG(z) = \sum_{n, l} {i \ket{n, l} \bra{n, l} \over z - E_n} + \sum_l \int_{0}^\infty d\rho {i \ket{\rho, l} \bra{\rho, l} \over z - \rho}
\end{align}

This object is obviously confusing due to the following observations:
\begin{itemize}
\item \emph{Observation 1}: $\tG(z)$ is not well defined for $z = E_n$.  
\item \emph{Observation 2}: $\tG(z)$ is not well defined on the real axis, for similar reasons.
\end{itemize}

This means that the green function for real energies is not well defined for all energies.  Instead, we will try to define the following operator:
\begin{align}
\tG^\pm(E) \equiv \lim_{\epsilon \rightarrow 0} \tG(E \pm i \epsilon)
\end{align}
This operator corresponds to the causal green function and anti-causal green function respectively.  The reason is that the $\pm i \epsilon$ kills $ t \rightarrow \mp \infty$ solutions respectively (adds damping).
 
Let's analyze this operator more carefully and list some observations:
\begin{itemize}
\item \emph{Observation 3}: $\tG^\pm(E_n)$ is still undefined.  This is because the first term would be a singular projection operator:
$$\lim_{\epsilon \rightarrow 0}\tG^\pm(E_n + i \epsilon) = \sum_l \underbrace{{i \ket{n, l} \bra{n, l}}}_{\text{Projection}} \times \underbrace{{1 \over 0}}_{\infty}$$.
\item \emph{Observation 4}: $\tG^\pm(E)$ is well defined on the positive axis, but $\tG(z)$ has a branch cut on the real axis
\end{itemize}

In fact, for observation 3, while $\tG(E_n \pm i \epsilon)$ is undefined even the limit of $\epsilon \rightarrow 0$, we can still investigate the function $\tG(z)$.  From complex analysis, one can integrate around the poles.  If we do so for $\tG(z)$, we get a projector operator
$$\oint_{z = E_n} \tG(z) {dz} =  -2 \pi \sum_{l} \ket{n, l} \bra{n, l}$$

For observation 4, we can show this by computing the size of the branch cut:
\begin{align}
\tG^+ - \tG^- &= \lim_{\epsilon \rightarrow 0} (\tG(E + i \epsilon) - \tG(E- i \epsilon)) \\
& = \lim_{\epsilon \rightarrow 0}\sum_l \int_0^\infty \underbrace{2 \epsilon \over (E - \rho)^2 + \epsilon^2}_{\text{\color{blue} Lorentzian}} \ket{\rho, l} \bra{\rho, l}
\end{align}

The lorentzian shown is actually a delta function in the limit of $\epsilon \rightarrow 0$:
\begin{align}
 \int {2 \epsilon \over x^2 + \epsilon^2} dx & = 2 \pi \\
\rightarrow  \lim_{\epsilon \rightarrow 0}  {2 \epsilon \over x^2 + \epsilon^2} &= 2 \pi \delta(x)
\end{align}

Using this identity, we can compute the size of the branch cut: it is just the projection operator onto the energy subspace $E$
\begin{align}
\tG^+(E) - \tG^-(E) \text{(E on positive real axis)} &= 2\pi \sum_l \int_0^\infty d\rho  \delta(\rho - E) \ket{\rho, l} \bra{\rho, l} \\
 &=2 \pi \sum_l \ket{E, l} \bra{E, l} 
\end{align}

\paragraph{Interpretation}:
\begin{itemize}
\item The Green operator $\tG(z)$ as a complex function has poles that correspond to the discrete spectrum of the hamiltonian, and a branch cut on the real axis corresponding to the discontinuity between causal and anti-causal solutions.  
\item The fact that the bound states correspond to poles is due to the fact they are \emph{stationary}.  They have un-damped excitations that run infinitely in time.  In fact, this can be seen in regular ODE's.  For example, an undamped spring has a oscillation that never dies in time.  That oscillation is called the normal mode of the spring, and if one computes the transfer function (the fourier transform of the green function or impulse response function) of the spring, you would get singularities at driving frequencies corresponding to the resonance frequency.
\item The fact causal and anti-causal solutions differ is known from regular ODE due to the fact the original operator has a non-trivial homogeneous solution (another way to say is the operator $(E - \hat{H})$ has a non-zero kernel for that energy.  In the continuous spectrum case, this corresponds to the fact that that E is an energy eigenstates.  Because the free propagating states are not bound, they are not stationary and build up energy that blows up.  Relying on the spring analogy, consider a simple PDE like the wave equation.  The free propagating waves without a potential are not bound, yet they are eigenstates of the wave equation.  Those solutions for a given driving frequency (the green operator as a function of $E = \omega$) will have outward propagating wave and inward propagating wave solutions.  Those 2 solutions and their difference corresponds to the branch cut singularity in the green operator seen for the continuous spectrum.
\end{itemize}

These insights, obtained in the contex of single particle QM, will still transfer their usefulness in QFT (albeit with more confusion) so better flesh them out now.
\begin{figure}
  \includegraphics[width=\linewidth]{pic_zplane}
  \caption{Singularity structure of the green operator}
  \label{fig:boat1}
\end{figure}















\end{document}