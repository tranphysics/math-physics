\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}	% Para caracteres en espa√±ol
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{braket}
\usepackage{multirow,booktabs}
\usepackage[table]{xcolor}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{wrapfig}
\usepackage{setspace}
\usepackage{calc}
\usepackage{multicol}
\usepackage{cancel}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\newlength{\tabcont}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}
\usepackage{empheq}
\usepackage{framed}
\usepackage[most]{tcolorbox}
\usepackage{xcolor}
\colorlet{shadecolor}{orange!15}
\parindent 0in
\parskip 12pt
\geometry{margin=1in, headsep=0.25in}
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{reg}{Rule}
\newtheorem{exer}{Exercise}
\newtheorem{note}{Note}
\begin{document}
\setcounter{section}{8}
\title{QFT Gifted amateur}

\thispagestyle{empty}

\begin{center}
{\LARGE \bf QFT for gifted amateur probelms}\\
2023
\end{center}


\section{Problems}
\subsection{Problem 2.3}

\begin{align}
x_j & \equiv {1 \over \sqrt{N}} \sum_k e^{i j k a} \tilde{x}_k \\
&= {1 \over \sqrt{N}} \sum_k  \sqrt{\hbar \over 2 m \omega_k} e^{i j k a} \left(a_k + a^{\dagger}_k \right) \\
&= {1 \over \sqrt{N}} \sum_k \sqrt{\hbar \over 2 m \omega_k} \left( a_k e^{ijka} + \underbrace{a^{\dagger}_{-k} e^{-ijka}}_{\text{swap k $\rightarrow$ -k}} \right)
\end{align}

\subsection{Problem 3.3}

First we will calculate $\frac12 m \omega^2 x_1^2 + {1 \over 2 m} p_1^2$:

\begin{align}
x_1 &\equiv \sqrt{\hbar \over 2 m \omega} (a_1 + a_1^\dagger) \\
p_1 &\equiv -i \sqrt{m \omega \hbar \over 2} (a_1 - a_1^\dagger) \\
\frac12 m \omega^2 x_1^2 + {1 \over 2 m} p_1^2 &=  \hbar \omega (\frac12 (a_1 a_1^\dagger + a_1^\dagger a_1)) \\
& = \hbar \omega \left(a_1^\dagger a_1 + \frac12 \right)
\end{align}

Since the "1" above is just label, it follows this must be true for "2" and "3" as well so that:
\begin{align}
\hat{H} = \hbar \omega \sum_{n=1}^3 \left(a_n^\dagger a_n + \frac12 \right)
\end{align}

To prove the next step, first note that $[b_0, b_{\text{anything else}}] = 0$ because $a_3$ commutes with $a_2, a_1$.  
Also note $[b_0, b_0^\dagger] = 1$.

Therefore, $[b_i, b_j^\dagger] = \delta_{ij}$ holds for i = 0.

For $i=-1, +1$, we only have to check, the following 3 calculations:

\emph{Calculation 1:}
\begin{align}
[b_{-1}, b_{+1}^\dagger] & = -\frac12 [a_1 +  i a_2, a_1^\dagger + i a_2^\dagger] \\
& = \frac12 \left( [a_1, a_1^\dagger] - [a_2, a_2^\dagger] \right) = 0
\end{align}

\emph{Calculation 2:}
\begin{align}
[b_{-1}, b_{-1}^\dagger] & = \frac12 [a_1 +  i a_2, a_1^\dagger - i a_2^\dagger] \\
& = \frac12 \left( [a_1, a_1^\dagger] + [a_2, a_2^\dagger] \right) = 1
\end{align}

\emph{Calculation 3:}
\begin{align}
[b_{+1}, b_{+1}^\dagger] & = \frac12 [a_1 -  i a_2, a_1^\dagger + i a_2^\dagger] \\
& = \frac12 \left( [a_1, a_1^\dagger] + [a_2, a_2^\dagger] \right) = 1
\end{align}

We now calculate the claimed hamiltonian:

\begin{align}
\hbar \omega \sum_m \left(b_m^\dagger b_m + \frac 12 \right) & = \hbar \omega (a_3^\dagger a_3 ) + \frac32 
\hbar \omega \times \frac12 (a_1^\dagger a_1 + a_2^\dagger a_2 + \text{cross terms}) + 
\hbar \omega \times \frac12 (a_1^\dagger a_1 + a_2^\dagger a_2 + \text{cross terms}) \\
& = \hbar \omega \sum_n (a_n^\dagger a_n + \frac12)
\end{align}

To check the 2nd claim, we note that the $m=0$ term goes away, while the $m=1$ and $m=-1$ term subtract.  This means we keep the cross terms from the previous calculation:

\begin{align}
\hbar \sum_{m=-1}^{+1} m b_m^\dagger b_m &= \hbar ( b_{+1}^\dagger b_{+1} - b_{-1}^\dagger b_{-1}) \\
& = -i \hbar \left(a_1^\dagger a_2 - a_2^\dagger a_1 \right) = \hat{L}^3
\end{align}

\emph{Commentary}

This problem illustrates a special case of the more general symmetry of the 3-d harmonic oscillator hamiltonian under U(3) group:
\begin{align}
\mathbf{a} \equiv (a_1, a_2, a_3)  \\
\rightarrow \mathbf{U} \mathbf{a} \rightarrow \hat{H} \rightarrow \hat{H}
\end{align}


\newpage
\subsection{Problem 5.4}

\begin{align}
L =-mc^2 \sqrt{1 - {v^2 \over c^2}} \approx -mc^2 \left(1 - {v^2 \over 2 c^2} \right) \approx -mc^2 + \frac12 m v^2 
\end{align}


\begin{align}
p & \equiv {\partial L \over \partial \dot{q}} \\
&= mv
\end{align}

\begin{align}
H &\equiv p \dot{q} - L \\
&= mv^2 - (-mc^2 + \frac12 mv^2) = mc^2 + \frac12 m v^2
\end{align}

\subsection{Problem 5.8}

Note that the electromagnetic field tensor, doing $\epsilon^{\alpha \beta \gamma \delta} F_{\gamma \delta}$ basically swaps $ E \rightarrow -B$ and $B \rightarrow -E$.

Then we are asked to compute $F_{\alpha \beta} \left(\epsilon^{\alpha \beta \gamma \delta } F_{\gamma \delta} \right)$ which is just the sum of all the matrix entries element wise multiplied, which gives:
$\propto \sum_{i=1}^3 E_i (-B_i) \propto E \cdot B$

This $E \cdot B$ term is topological in nature. The way to see it is in form notation, it can be written as $F \wedge F$.  Its integral over the manifold gives the winding number of the gauge field configuration and is a topological invariant.  It's integral over a closed manifold gives an integer (up to factors of pi and 2).

Another comment: this term obviously violates parity (by nature of having the $\epsilon$ tensor). 

\subsection{Problem 5.9}

Consider the equation:
$ \partial_{\mu} F^{\mu \nu} = J^{\nu}$ for $\nu = 0$

This gives:

\begin{align}
\partial_{x} E_x + \partial_y E_y + \partial_z E_z = \rho \text{ (Gauss's Law)}
\end{align}

Let's work out the same equation for $\nu = 1$ (x) component:

\begin{align}
 \partial_t E_x + \partial_y B_z - \partial_z B_y = J_x \\
\partial_t E_y - \partial_x B_z + \partial_z B_x = J_y \\
\text{et cetera} \\
\rightarrow \nabla \times \mathbf{B} + \partial_t \mathbf{E}  = \mathbf{J}
\end{align}

The bianchi's identity below:

\begin{align}
\partial_{[\mu}F_{\nu \lambda]} = 0
\end{align}

follows straight from the definition of F:

\begin{align}
F_{\nu \lambda} = \partial_{\nu} A_{\lambda} - \partial_{\lambda} A_{\nu}
\end{align}

A way to see it is that an exact form is necessarily closed:
$F = d A \rightarrow dF = 0$.

In particular for the spatial components $\mu, \nu, \lambda = 1, 2, 3$ it implies:
\begin{align}
\nabla \cdot \mathbf{B} = 0
\end{align}
which is one of maxwell's equations (no magnetic monopoles).

For the combination $\mu, \nu, \lambda = 0, (1 \rightarrow 3), (1 \rightarrow 3)$ where $\nu \neq \lambda$, we can for example use the case $0, 1, 3$ to get the following equation:

\begin{align}
\partial_0 F_{13} + \partial_{1} F_{30} + \partial_3 F_{01} &= 0 \\
\partial_t B_y - \partial_x E_z + \partial_z E_x = 0 \\
\end{align}

We can work out the 2 other cases for $B_x, B_z$ to get Faraday's law:

\begin{align}
\partial_t \mathbf{B} + \nabla \times \mathbf{E} = 0.
\end{align}

\subsection{Problem 5.10}

F is a anti-symmetric object.  It is contracted with symmetric tensor $\partial_\alpha \partial_\beta$ which implies that the result is 0
(this is because for every term, there is a term of opposite sign).

The continuity equation is a statement about conservation of charge:

\begin{align}
\partial_t \rho = - \nabla \cdot \mathbf{J} \rightarrow {d  \over dt} \underbrace{\int_{M} \rho dV}_{\text{charge in region "M"}} = - \underbrace{\int_{\partial M} \mathbf{J} \cdot d \mathbf{A}}_{\text{current flowing out of the boundary of }M}
\end{align}

\subsection{Problem 8.2}
Set $\hbar = 1$ for simplicity.
\begin{align}
a_k^{\dagger}(t) &= U^{-1} a_k^{\dagger}(0) U \\
& = \exp(i H t) a_k^{\dagger} \exp(-i Ht)\\
& = \exp(i \sum_{k'} E_{k'}\hat{N}_{k'} t ) a^{\dagger}\exp(-i \sum_{k'} E_{k'} \hat{N}_{k'} t )
\end{align}

Since the operators commute for $k' \neq k$, we only need to consider the term where k' = k.

We invoke the BCH formula to evaluate:

\begin{align}
a^{\dagger}_k(t) &= a_k^{\dagger}(0) + [i t E_k N_k, a_k(0)] + \frac12  [i t E_k N_k, [i t E_k N_k, a_k(0)]] + ... \\
& = a_k^{\dagger}(0) \times \left(\sum_{n = 0}^{\infty} {(it E_k)^n \over n!} \right) \\
& = a_k^{\dagger}(0) \times \exp(i E_k t)
\end{align}

It follows

\begin{align}
a_k(t) = a_k(0) \exp(-i E_k t)
\end{align}

\subsection{Problem 9.1}

\begin{align}
\hat{U} = e^{-i \hat{p}a} \rightarrow {\partial \over \partial a} \hat{U}|_{a= 0} = {i \hat{p}} \underbrace{U(0)}_{1} \rightarrow \hat{p } = {-1 \over i} {\partial \hat{U} \over \partial a}
\end{align}

\subsection{Problem 9.2}

\begin{equation*}
\Lambda(\phi_1) = 
\begin{pmatrix}
\cosh(\phi) & \sinh(\phi) & 0 & 0 \\
\sinh(\phi) & \cosh(\phi) & 0  & 0\\
0 & 0 & 0  & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}
\end{equation*}

\begin{align}
{\partial \over \partial \phi_1}|_{\phi_1 = 0} = 
\begin{pmatrix}
0 & 1& 0 & 0 \\
1 & 0 & 0  & 0\\
0 & 0 & 0  & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}
\end{align}

The other generators are obtained trivially by plugging "1" into the location $\Lambda^{0}_{j}$ and $\Lambda^{j}_{0}$ with $j = 1,2,3$.   Add the ${1 \over i}$ to get the answer.  Note how the generator are anti-hermitian (which makes the lie group non-compact).

\subsection{Problem 9.4}

\begin{align}
\omega^{\mu}_\nu x^\nu \partial_\mu & = \omega_{\mu \nu} x^\nu \partial^\mu \\
& = \underbrace{\frac12 \omega_{\mu \nu} x^\nu \partial^\mu + \frac12 \omega_{\mu \nu} x^\nu \partial^\mu}_{\text{split in 2}} \\
& = \frac12 \omega_{\mu \nu} x^\nu \partial^\mu \underbrace{- \frac12 \omega_{\nu \mu}}_{\text{anti-symmetry}} x^\nu \partial^\mu \\
& = \frac12 \omega_{\mu \nu} \left(x^\nu \partial^\mu - \underbrace{x^\mu \partial^\nu}_{\text{swap index}} \right)
\end{align}

\begin{align}
f(x') &= 1 + a^\mu \partial_\mu f(x) + \frac12 \omega_{\mu \nu}  \left(x^\nu \partial^\mu - x^\mu \partial^\nu \right) \\
& = 1 + i a^\mu \underbrace{(i \partial_\mu)}_{p_\mu} f(x) + {i \over 2 } \omega_{\mu \nu} \times \underbrace{ -i \left(x^\nu \partial^\mu - x^\mu \partial^\nu \right)}_{M^{\mu \nu}} f(x)
\end{align}

Because $\frac12 M^{\mu \nu}$ is the generator of lorentz transformation, the equation follows:

\begin{align}
\Lambda = \exp(-{i \over 2} \omega_{\mu \nu} M^{\mu \nu} )
\end{align}


\subsection{Why keep factors of $\hbar$}

One reason to keep factors of $\hbar$ around is to clarify when doing a semi-classical expansion. The classical limit of the quantum theory is obtained by taking $\hbar \rightarrow 0$, so in some sense, a classical expansion usually is carried out with an expansion around ${1 \over \hbar}$.

\paragraph{Example: WKB approximation}

The WKB approximationj is an expansion in $\hbar$ with the first order producing tunneling amplitude.  In some sense, it reproduces, it is a semi-classical expansion because as the wavelength decreases relative to the size of the variation of the potential term (large action relative to $\hbar$), the expansion becomes more accurate.

$$\psi(x) \propto \exp \left({i \over \hbar} \left(\int dx p(x) + \underbrace{\sum_{n=1}^\infty \hbar^n S_n}_{\text{higher order WKB terms}}  \right) \right) $$
$$ p(x) \equiv \sqrt{2 m (E-V(x))}$$

\paragraph{Example: Saddle point integration of the path integral}

Consider the typical path integral for some transition amplitude
$$\braket{\psi_f | e^{i Ht \over \hbar} | \psi_i} \equiv \int \mathcal{D} \phi \exp\left( {i \over \hbar} S[\phi] \right)$$
This amplitude can be approximated using the saddle point method around the path of least action $\phi_0$ (a minimum) in the limit of $\hbar \rightarrow 0$.  To do so, we parametrize field fluctuations around the minimum path:
$$ \phi(x)=\phi_0 + \sqrt{\hbar \over i} \epsilon(x)$$
where fluctuations $\epsilon$ is order 1 and we explicitly keep $\hbar$ to to show the expansion is small.

$$S[\phi] \approx \underbrace{S[\phi_0]}_{S_0} + {\hbar \over i} \underbrace {{\delta^2 \over \delta \phi(x) \delta \phi(y)} S[\phi]}_{\text{Hessian of S}} \epsilon(x) \epsilon(y) + ...$$
$$ \braket{\psi_f | e^{i Ht \over \hbar} | \psi_i} \approx \exp\left({i \over \hbar} S_0 \right) \exp \left(\frac12 \text{Tr} \ln({\delta^2 \over \delta \phi(x) \delta \phi(y)} S[\phi]\right) \int \mathcal{D}\phi \text{...} $$

The expansion in the limit $\hbar$ goes to 0 shows that the saddle point contribution is the dominant classical limit amplitude.


\subsection{Canonical quantization}

\paragraph{Why is setting the commutation relation between conjugate variables to $i \hbar$ the correct recipe to obtaining a quantum theory from a classical theory?}

There are many ways to attack this issue.  The most simple way I can think of quantizing a field is to realize that QFT is just the quantum theory of a continuum of particles.  Consider the classical theory of a single particle, with coordinate $\phi_1$ and momentum $\dot{\pi}_1$ with a hamiltonian of a harmonic oscillator:
$$H_1 = \frac12 m \omega^2 \phi_1^2 + \frac12 m \dot{\phi_1}^2 = \frac12 m \omega^2 \phi_1^2 + {\pi_1^2 \over 2 m} $$

The quantum theory of this single particle in a spring is described by a hamiltonian operator:

$$\hat{H}_1 = \frac12 m \omega^2 \hat{\phi}_1^2 + {\hat{\pi}_1^2 \over 2 m}$$
where $\hat{\phi}_1, \hat{\pi}_1$ are position momentum operators with commutation relation
$$ [\hat{\phi}_1, \hat{\pi}_1] = i \hbar$$


Now let's try to take a limit of an infinite number of springs connected together.  This is the theory of a solid lattice:

\subsection{Time dependent Hamiltonian}

The \emph{retarded} propagator $G^+(x, x', t, t')$ is defined as position space basis representation of the time evolution operator $\mathbf{U}$, restricted to positive times:


\begin{align}
\mathbf{U} (t, t') \ket{\psi(t')} &\equiv \ket{\psi(t)} \\
G^+(x, x', t, t') &\equiv \bra{x} \mathbf{U}(t, t') \ket{x'} \theta(t - t')
\end{align}

We can show that the time evolution operator satisfies schrodinger equation in operator form as:
\begin{align}
\mathbf{H U} = i \partial_t \mathbf{U}
\end{align}
In the text, if you use this relation you can show the retarded propagator satisfies a schrodinger PDE as well:
\begin{align}
\mathbf{H} G^+(x, x', t, t') = i \partial_t G^+ + i \delta(x - x') \delta(t - t')
\end{align}

where here the notation $\mathbf{H} G^+$ is understood as the operator H acting on the function G in the coordinate x and t (for example, if H had momentum squared terms, you'd get $\partial_x^2$ operator).

\subsection{Time-independent Hamiltonian}

In the case where the hamiltonian is time independent, we can obtain more interesting relations.  One particular representation we will derive is the fourier representation of the retarded propagator gives key information about the eigenfunctions and eigenvalues of the (time-independent) hamiltonian.

First, WLOG, set $t' = 0$.

If $\mathbf{H}(t) = \mathbf{H}$, $\mathbf{U}(t, t' = 0) = e^{-i \mathbf{H} t}$.
We now derive the fourier decomposition of the retarded propagator (which is a function of 3 variables now, initial and end position and time):

\begin{align}
G^+(x, x', t) &\equiv \braket{x} e^{-i \mathbf{H}t} \ket{x'}  \theta(t) \\
& \text{ ( insert complete set of eigenfunctions of $\mathbf{H}, \mathbf{I} \equiv \sum_n \ket{n} \bra{n}$ )} \\
& = \sum_n \braket{x | n} \bra{n}e^{-i \mathbf{H}t} \ket{n'} \braket{n' | x'} \theta(t) \\
\end{align}

Note $\mathbf{H}$ is diagonal in the $\ket{n}$ basis.  Define $\phi_n(x) \equiv \braket{x | n}$.  This becomes

\begin{align}
G^+(x, x', t) &=\theta(t) \sum_n \phi_n(x) \phi_n^*(x') e^{- i E_n t} 
\end{align}

The next step is to compute the fourier transform of $G^+$ with respect to time.  This would be straightforward, if not for the pesky $\theta$ factor, so we have to establish a few basic facts about complex integration.

We can re-express the exponential in this expression using the Cauchy integral formula.  Let's first establish a math fact as follow.
Consider the function f(E) below (this function is called a "Resolvent"):
\begin{align}
f(E) = \int_{-\infty}^\infty dz {e^{- i z t} \over z - E + i \epsilon}
\end{align}
It turns out this function neatly expresses the $\theta$ function due to the fact it is discontinuous from $t<0$ to $t>0$.  In fact, it is:
\begin{align}
f(E) = - 2 \pi i \theta(t) e^{- i E t}
\end{align}

\paragraph{digression on math identity}
\emph{
The way to see this math identity is that $ t < 0$, we can close the contour in the upper half plane.  This contour doesn't contain the $E - i\epsilon$ pole and therefore the closed curve integral is 0.  When $t > 0$, we have to close the contour in the lower half plane to make the semicircle contribution decay, and this cause the closed contour integral to contain the $E - i \epsilon$ pole, giving a non-zero contribution.  This is where the $\theta(t)$ factor comes in.}

Anyways using this identity, we can neatly repackage equation 63:

\begin{align}
G^+(x, x', t) = {i \over 2 \pi}\int_{-\infty}^\infty dz \sum_n {\phi_n(x) \phi_n^*(x') e^{-i zt} \over z - E_n + i \epsilon}
\end{align}

Equation 66 is actually a fourier decomposition formula (with $E = - \omega$).  It shows that the fourier transform of the retarded propagator with respect to time is $\tilde{G}$ as defined below:

\begin{align}
G^+(x, x', t) \equiv \int dE e^{-i E t} \tilde{G}(x, x', E) \\
\tilde{G}(x, x', E) = \sum_n {i \phi_n(x) \phi_n^*(x') \over E - E_n + i \epsilon}
\end{align}

Furthermore, note that $\tilde{G}(x, x', E)$ in the expression above is the coordinate representation of some abstract operator $\mathbf{\tilde{G}}$
\begin{align}
G(x, x', E) \equiv \braket{x| \mathbf{\tilde{G}}(E)| x'} \text{ (for some operator $\mathbf{\tilde{G}}$}
\end{align}
This abstract operator $\mathbf{\tilde{G}}$ is actually diagonal in the eigenfunction basis of the hamiltonian:
\begin{align}
\mathbf{\tilde{G}}(E) = \sum_{n} {i \ket{n} \bra{n} \over E - E_n + i \epsilon}
\end{align}

In particular, in this basis, it is obvious that the following equation holds:
\begin{align}
(E - \mathbf{H}) \mathbf{\tilde{G}}(E) =i \mathbf{I}
\end{align}

The coordinate representation of the equation above is:
\begin{align}
(E - \mathbf{H}) \tilde{G}(x, x', E) = i \delta(x - x')
\end{align}
(it is understood $\mathbf{H}$ operator applies on the coordinate x, leaving x' intact).  This means that the operator equation for $\mathbf{\tilde{G}}$ actually implies that the function $\tilde{G}(x, x', E)$ is some sort of impulse response function (green function), but for a different equation.  This equation is:
$$\mathbf{H} G = E G$$

Lo and behold, this equation is the \emph{time-independent} Schrodinger's equation!  So the fourier transform with respect to time of propagator for the time-independent hamiltonian gives the green function for the time-independent schrodinger's equation.
This is not surprising at all.  The time-independent schrodinger's equation is a separable PDE and we solve it via exponentials. 
\begin{align}
\mathbf{H} \psi(x, t) &= i \partial_t \psi(x, t) \\
\rightarrow \psi(x, t) &= \phi(x) e^{-i E t} \\
\rightarrow \mathbf{H} \phi(x) & = E \phi(x)
\end{align}

The general time evolution of the wavefunction for time-independent Hamiltonian is known to be from intro QM:
\begin{align}
\psi(x, t) = \sum_n \phi_n(x) \braket{n|\psi(0)} e^{-i E_n t} \\
\end{align}

For a delta function initial condition $\delta(x-x_0)$ (green function definition), you have:
\begin{align}
\psi(x, t) = \sum_n \phi_n(x) e^{- i Et} \braket{n|x_0} = \sum_n \phi_n(x) \phi_n^*(x_0) e^{-i Et}
\end{align}

The fourier transform components of this object solves the time independent schrodinger equation since they are the $\phi$'s.











\end{document}